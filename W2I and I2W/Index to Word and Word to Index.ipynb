{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled50.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQjCOhFy7bjU",
        "colab_type": "text"
      },
      "source": [
        "# **Index - Word and Word - Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O85es0s1a6b",
        "colab_type": "text"
      },
      "source": [
        "# **Word to Index**\n",
        "Word to Index is one of the vectorization strategies in NLP. We cannot feed the words directly into model for prediction. We have to convert it into the language which the machine can understand and that is NUMBERS! In this post I have implemented Word 2 Index strategy. Every word is converted to one hot vector based on its index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlWOz8VOqMgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "65cc1567-22f6-444e-eb02-551e704e7a6c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "import numpy as np"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE_j9Ma1q_2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=brown.words(categories='news')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32GBUuTM2RYg",
        "colab_type": "text"
      },
      "source": [
        "I am using the words from the BROWN corpus. It is already loaded in NLTK package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVsHBN2YreLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_freq = nltk.FreqDist(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i5tQHTo2cKV",
        "colab_type": "text"
      },
      "source": [
        "Now I have created a frequency distribution of words. Lets see how many times the word \"The\" and \"is\" are used in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5b2F0BZ2a9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be29663e-d5c3-4f28-ea72-80185f15f606"
      },
      "source": [
        "print(word_freq['The'])\n",
        "print(word_freq['is'])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806\n",
            "732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCVcICCT2sSN",
        "colab_type": "text"
      },
      "source": [
        "We know that the words \"The\" and the word \"the\" are same, but the machine treats both the words separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnAiKJ5Nr_kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8078599f-bdc1-4b6a-e747-dfc10b1b822a"
      },
      "source": [
        "print(word_freq['The'])\n",
        "print(word_freq['the'])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806\n",
            "5580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR1jAeBnsVmj",
        "colab_type": "text"
      },
      "source": [
        "If we use the same frequency distribution in our model, it would not work properly since the words \"The\", \"the\", \"THE\" are all considered seperately even though semanticallyu they are same. So its important for us to make the machine understand the words are same and that can be done by converting all the words in one format. Lets convert all the words to lower case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGV4UWvzsTLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lower_words = [w.lower() for w in words ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8uCehytmKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab0e1700-51fb-4b65-e7ac-6c999cbbf51f"
      },
      "source": [
        "print(lower_words[:10])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvf_xNCB3cWZ",
        "colab_type": "text"
      },
      "source": [
        "We saw above that all the words are converted to same format and Lets make Frequency distribution on these words now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUFM_K7Os5GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_freq = nltk.FreqDist(lower_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4fypqNPszpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eee35acd-2eaf-443a-a5d9-a423516b1fdc"
      },
      "source": [
        "print(word_freq['The'])\n",
        "print(word_freq['the'])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "6386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJPqqiX73oWq",
        "colab_type": "text"
      },
      "source": [
        "Now we see that The words \"The\", \"the\", \"THE\" all are treated same by Machine and we are heading in right direction. Now lets convert these words to index. Here we saw above that the first 10 words are **'the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of'** we want to convert these words into numbers [0,1,2,3,4,5,6,7,8,9]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLfyaU8s8f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_2_index = [[j,i] for i,j in enumerate(word_freq)]\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9kEC6v74I1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "52474e86-e934-4779-80ad-93ce2cd84e51"
      },
      "source": [
        "word_2_index[:10]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 0],\n",
              " ['fulton', 1],\n",
              " ['county', 2],\n",
              " ['grand', 3],\n",
              " ['jury', 4],\n",
              " ['said', 5],\n",
              " ['friday', 6],\n",
              " ['an', 7],\n",
              " ['investigation', 8],\n",
              " ['of', 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-nqHKqa4RZO",
        "colab_type": "text"
      },
      "source": [
        "Lets create dictionary of the word_2_index so that we can access it easily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep7S8ShkvIWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = dict(word_2_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec1V5mrSv28b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a1f3077-4e2e-4f59-c7a9-52a40328d4e7"
      },
      "source": [
        "print(w['the'], w['fulton'], w['county'], w['grand'])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve0WjoY_4mNR",
        "colab_type": "text"
      },
      "source": [
        "Looking at the above output we can see that the words are converted to numbers. Now lets see how if I have a sentence, How is it converted into Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIa74D3UwO73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d00d532b-e865-41d1-a5d3-101987d22208"
      },
      "source": [
        "sentence= 'which is the best place'\n",
        "sentence= sentence.split()\n",
        "vector = [w[l] for l in sentence]\n",
        "print(sentence)\n",
        "print(vector)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['which', 'is', 'the', 'best', 'place']\n",
            "[33, 136, 0, 117, 23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGJuaPcc438v",
        "colab_type": "text"
      },
      "source": [
        "We arent done yet!!!!! When we are passing input to the Neural Network, it will undergo various multiplication operations and so we will convert all these words into ONE HOT VECTORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-myh_Yyi7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "one_hot_vector =[]\n",
        "for i in w:\n",
        "  a= np.zeros(13112)\n",
        "  a[w[i]]=1\n",
        "  one_hot_vector.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bruxR0c5lyQ",
        "colab_type": "text"
      },
      "source": [
        "Lets see now how the sentence **this is the** is converted to one hot vector and can be fed into ML model for further modelling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkX0gXIy0ptG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d4984aa4-4576-4f01-b958-1d960002a9ee"
      },
      "source": [
        "s=\"this is the\"\n",
        "s= s.split()\n",
        "X = [one_h_v[w[v]] for v in s]\n",
        "X"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              " array([0., 0., 0., ..., 0., 0., 0.]),\n",
              " array([1., 0., 0., ..., 0., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4K5zSxW68in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_2_word = [[i,j] for i,j in enumerate(word_freq)]\n",
        "index_2_word = dict(index_2_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qkUXfUh6F-w",
        "colab_type": "text"
      },
      "source": [
        "Now if we want to convert these one hot vectors into WORDS.Lets see how its done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPkvx4LP6Qvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8a1e63a0-ef56-4183-a116-d695334d3e22"
      },
      "source": [
        "for i in range(len(X)):\n",
        "  print(index_2_word[np.argmax(X[i])])\n",
        " "
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this\n",
            "is\n",
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039shr8R7uLI",
        "colab_type": "text"
      },
      "source": [
        "What if we have the words that are not in Vocabulary??????? For that we can create UNKNOWN tag and add such words into that!"
      ]
    }
  ]
}